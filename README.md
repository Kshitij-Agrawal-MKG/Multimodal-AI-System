# ğŸ–¼ Multimodal AI System for Custom Output Generation

## ğŸ“Œ Project Overview
The **Multimodal AI System** is a **Streamlit-based web application** that allows users to:
- **Upload an image**.
- **Generate a detailed or creative description** of the image using AI.
- **Extract text from the image** using OCR (Optical Character Recognition).
- **Translate the generated description** into multiple languages (Hindi, Tamil, Telugu, Marathi, Bengali, and English).

This project integrates **Computer Vision**, **Natural Language Processing (NLP)**, and **Machine Translation** to provide a **multimodal AI experience**.

---

## ğŸš€ Features
- **Image Captioning** ğŸ–¼ â AI generates descriptions for uploaded images.
- **Text Extraction (OCR)** ğŸ“„ â Extracts text from images using Tesseract.
- **Custom Prompts** ğŸ“ â Users can define how they want the AI to describe the image.
- **Multi-Language Support** ğŸŒ â The AI-generated description can be translated into multiple languages.
- **Interactive UI** ğŸ¨ â Uses Streamlit for a clean and user-friendly interface.

---

## ğŸ—ï¸ **Project Structure**

ğŸ“‚ **Multimodal-AI**

- `app.py`               â€” Streamlit UI for user interaction
- `llm.py`               â€” Uses AI models to generate image descriptions
- `trans.py`             â€” Handles text translation using Microsoft Translator API
- `visionai.py`          â€” Performs OCR and image captioning
- `requirements.txt`     â€” List of required Python packages
- `README.md`            â€” Project documentation


---

## ğŸ›  **Installation Guide**
Follow these steps to set up the project on your local machine.

### 1ï¸âƒ£ **Clone the Repository**
```bash
git clone https://github.com/yourusername/Multimodal-AI-System.git
cd Multimodal-AI-System
```


### 2ï¸âƒ£ **Set Up a Virtual Environment (Optional but Recommended)**
```bash
python -m venv env
source env/bin/activate   # On macOS/Linux
env\Scripts\activate      # On Windows
```

### 3ï¸âƒ£ **Install Dependencies**
```bash
pip install -r requirements.txt
```

### 4ï¸âƒ£ **Run the Application**
```bash
streamlit run app.py
```
This will start a **local web server**, and you can access the app in your browser.

---

## ğŸ“ **How It Works**
1. **Upload an Image** ğŸ–¼ â Select an image file (`.jpg`, `.png`, `.jpeg`).
2. **Enter a Custom Prompt** ğŸ“ â Describe how you want the AI to interpret the image.
3. **Process the Image** ğŸš€ â Click on the "Process Image & Generate Output" button.
4. **View the AI-Generated Description** ğŸ” â The system will display:
   - AI-generated caption.
   - Extracted text from the image (OCR).
   - Translated output (if selected).
5. **Choose a Language** ğŸŒ â Translate the output into Hindi, Tamil, Telugu, Marathi, Bengali, or English.

---

## ğŸ“œ **Detailed Explanation of Scripts**

### 1ï¸âƒ£ **`app.py` (Main Web App)**
- **Uses Streamlit** to create an interactive web interface.
- **Handles file uploads**, user input, and language selection.
- **Calls `llm.py` to generate AI-based descriptions**.
- **Calls `trans.py` to translate the descriptions**.

### 2ï¸âƒ£ **`llm.py` (AI-Based Image Captioning)**
- Uses **Salesforce's BLIP model** to generate an image caption.
- Extracts **text using OCR (Tesseract)**.
- Sends a **customized request** to the AI model via **Groq API**.
- Uses **LLaMA 3.3-70B** to **generate detailed descriptions** based on user input.

### 3ï¸âƒ£ **`trans.py` (Text Translation)**
- Uses **Microsoft Cognitive Translator API** to convert English descriptions into:
  - **Hindi, Tamil, Telugu, Marathi, and Bengali**.
- Sends a **POST request** to the **Microsoft Translator API** and retrieves the translated text.

### 4ï¸âƒ£ **`visionai.py` (Computer Vision & OCR)**
- **Image Captioning** â Uses **BLIP (Salesforce's model)** to generate descriptions.
- **Text Extraction (OCR)** â Uses **Tesseract** to extract text from the image.

---

## ğŸ”§ **Dependencies**
All required dependencies are listed in `requirements.txt`. Install them using:
```bash
pip install -r requirements.txt
```

---

## ğŸ”‘ **Environment Variables & API Keys**
To use **Microsoft Translator API** and **Groq API**, replace placeholders with your actual API keys:

- **Inside `trans.py` (Microsoft Translator API)**
  ```python
  key = "YOUR_MICROSOFT_TRANSLATOR_API_KEY"
  location = "YOUR_REGION"
  ```
  
- **Inside `llm.py` (Groq API)**
  ```python
  api = "YOUR_GROQ_API_KEY"
  ```

---

## ğŸš€ Live Demo  
[Click here to access the project](https://multiamodal-ai-system.streamlit.app/)

## ğŸ¥ **Demo Video**

ğŸ‘‰ **[Click here to watch the demo video](https://youtu.be/JduGvL-vdhM)** 




## ğŸ¤ **Contributing**
Feel free to contribute by:
- Fixing issues ğŸ› ï¸
- Adding new features ğŸš€
- Improving performance âš¡
- Creating better UI enhancements ğŸ¨

Fork the repository and submit a pull request.

---

## ğŸ“œ **License**
This project is **open-source** under the **MIT License**.

---

## ğŸ“§ **Contact**
If you have any questions, feel free to reach out:
- **Developer**: Kshitij Agrawal  
- **Email**: kshitiijagrawal53@gmail.com  
- **LinkedIn**: [Kshitij Agrawal](https://www.linkedin.com/in/kshitij-agrawal-319b36293/)


---

ğŸŒŸ **Star this repo if you find it useful!** â­
```
